{
  "hash": "ab5fd3202678391be551749a0f631d5f",
  "result": {
    "markdown": "---\ntitle: \"Tidy Mixed Models in R\"\nsubtitle: \"A simple guide to succeed on the analysis of common mixed models in agriculture\"\nauthor: \"Adrian Correndo\"\ndate: 10-19-2022\nabstract-title: 'Summary'\nabstract: 'This workshop provides a workflow to analyze common types of mixed models data in agriculture: (i) Split-Plots, and (ii) Repeated measures. From exploring the data to create a summary report with figures, we will cover how to write, test, and select from multiple candidate models at once using tidy principles, packages from the tidyverse|tidymodels framework, and all using the new Quarto features!'\nformat:\n  html:\n    code-tools: true\n    code-fold: true\n    code-summary: 'Show code'\n    code-link: true\n    theme: united\ntoc: true\ntoc-title: 'Contents'\ntoc-depth: 4\ntoc-location: left\nnumber-sections: false\nhighlight-style: pygments\nsmooth-scroll: true\nbibliography: ../references.bib\nlink-citations: TRUE\n---\n\n\n\n\n# What are Mixed Models?\n\nIn simple words, the rationale behind mixed models is the simultaneous presence of components that model the EXPECTED VALUE (fixed) as well as the VARIANCE (random).\n\nSpecifically, today we are going to cover LINEAR MIXED MODELS, which make the following assumptions [@Bolker_etal_2022]:\n\n-   The **expected values** of the responses are **linear combinations** of the fixed predictor variables and the random effects.\n\n-   The conditional distribution of the variable response is Gaussian (equivalently, the errors are \"Normal\").\n\n-   The random effects are normally distributed. Normally, we assume that the expected value of a random effect is equal to zero, but with a positive variance.\n\n::: callout-note\nWe ar going to employ the most used packages and/or functions for `frequentist` LMMs:\n\n-   **nlme**: nlme::lme() provides REML or ML estimation. Allows multiple nested random effects, and provides structures for modeling heteroscedastic and/or correlated errors (spoiler for repeated measures analysis). This is already part of base R.\n-   **lme4**: lmer4::lmer()) provides REML or ML estimation. Allows multiple nested or crossed random effects, can compute profile confidence intervals and conduct parametric bootstrapping.\n:::\n\nFor more information about mixed models in R, please, check out the new [CRAN Task View: Mixed, Multilevel, and Hierarchical Models in R](https://cran.r-project.org/web/views/MixedModels.html).\n\n# Why TIDY?\n\nWell, from the hand of [Tidyverse](https://www.tidyverse.org/), the \"tidy data\" framework changed the way we code and work in R for data science. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure [@wickham2014]:\n\n-   Each variable is a column,\n\n-   Each observation is a row, and\n\n-   Each value have its own cell.\n\n![](images/tidy-1.png) **Tidy-data structure**. Following three rules makes a dataset tidy: variables are in columns, observations are in rows, and values are in cells. Source: [@Wickham2017R].\n\n### Free HTML books\n\n::: {layout-ncol=\"2\"}\n[![](images/cover.png){height=\"300\"}](https://r4ds.had.co.nz/)\n\n[![](images/cover-01.png){height=\"300\"}](https://www.tmwr.org/)\n:::\n\n# Outline\n\nAfter planning the experimental design, identifying dependent variable, independent variable(s), conducting the experiment, and collecting the data...the expected path would be as follows:\n\n\n```{mermaid}\n%%| echo: true\n\nflowchart LR\n  A[Dig the data] --> B{Model Selection}\n  B --> C[Significant\\nEffects?]\n  subgraph Inference\n  C -->|Yes| D[Comparisons]\n  end\n  \n```\n\n\nThis workflow has been created using [mermaid](https://mermaid-js.github.io/mermaid/#/)\n\n# THE CODE\n\n## What do you need?\n\nFor a complete experience, I recommend you download and install the:\n\n-   [Latest version of R](https://www.r-project.org/)\n\n-   [Latest version of RStudio](https://www.rstudio.com/products/rstudio/download/)\n\n## What is Quarto?\n\nWe are going to explore the new features offered by [Quarto](https://quarto.org) documents (\\*.qmd).\n\n![](images/quarto.png)\n\nQuarto is a refined version (and successor) of [R-markdown](https://rmarkdown.rstudio.com/). It is an open-source scientific and technical publishing system built on [Pandoc](https://pandoc.org/). It allows to combine R, Python, Julia, and Java (Observable JS) for the design of reports, applications, websites, blogs, scientific publications, and more...\n\n# 00. PACKAGES\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| echo: true\n#| collapse: true\n\n#install.packages(\"easypackages\") # To load and/or install the packs\nlibrary(easypackages)\npackages(\"readxl\") # To open/save excel files\npackages('dplyr', \"tidyr\",\"purrr\", \"forcats\") # Data wrangling\npackages(\"broom\", \"broom.mixed\") # \npackages(\"stringr\") # Edit text lines\npackages(\"performance\") # Check assumptions and performance\npackages(\"nlme\", \"lme4\") # Mixed models\npackages(\"emmeans\",\"multcomp\",\"multcompView\",\n         \"car\", \"multilevelmod\") # Aov and mult comp\npackages(\"ggplot2\") # Figures\npackages(\"agricolae\") # Miscellaneous functions\n```\n:::\n\n\nAmong many packages we are going to use today, there is one from the [tidymodels family](https://www.tidymodels.org/) that was specially designed to convert statistical objects into tidy format: the *broom* package [@broom]. Particularly for mixed models, we will also need its `spinoff`: the *broom.mixed* package [@broom.mixed] .\n\n[![](images/logo-01.png){width=\"168\"}](https://broom.tidymodels.org/)\n\nThe broom package offer three key functions to manipulate models' outcomes:\n\n-   `glance()` to report information about the entire model\n\n-   `tidy()` to summarize information about model components, and\n\n-   `augment()` to add information about observations to a dataset\n\n# 01. SPLIT-PLOT\n\nSplit-plot arrangement is frequently used in experiments including several factors (factorial). The main characteristic is that the arrangement follows a hierarchy: there main plots (a.k.a. whole plots) covering one of the factors, and then there are \"subplots\" within each level of the main that include levels of a second factor, and so on. Therefore, the main plot serves as a \"block\" for the subplots, and thus, we are setting boundaries to (\"restricting\") the randomization of the subplot factor.\n\n::: callout-important\n-   **DESIGN**: We intentionally call split-plot \"arrangement\" because they can fit into multiple \"designs\" such as completely randomized (CRD), randomized complete blocks design (RCBD), or latin-squares design (LSD).\n\n-   **INFERENCE POWER**: What happens with split-plot design is that the main plot has less degrees of freedom than the factor at the subplot, and thus, we have more inference power at the factor in the subplot hierarchy (and the interaction). So consider this before it's too late!\n:::\n\n## Create a split-plot design\n\nThe *agricolae* package [@agricolae] brings a set of very useful functions to generate different experimental designs, among them, the split-plot. Let's see an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example with agricolae\n\n# Define plots\nmainplot <- c(0,50,80,110,140)\nsubplot <- c(\"Var_1\", \"Var_2\", \"Var_3\")\n\n# Produce\nsp_design <- agricolae::design.split(trt1 = mainplot, trt2 = subplot, \n                        design = \"rcbd\", r = 3, \n                        randomization = TRUE, seed = 4561)\n```\n:::\n\n\n## i. Data\n\nThe following is just a fake data set where we have a split-splot arrangement within an RCBD (BLOCK), where at the main plot corresponds to nitrogen rate (NRATE, with 5 levels), and the subplot to wheat variety (VARIETY, with 3 levels).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read csv\nsplit_plot_data_0 <- read.csv(file = \"../data/01_split_plot_data.csv\", header = TRUE)\n\n# File online? Try this...(remove \"#\")\n# url_split <- \"https://raw.githubusercontent.com/adriancorrendo/tidymixedmodelsweb/master/data/01_split_plot_data.csv\"\n\n# split_plot_data_0 <- read.csv(url_split)\n\n# Data hierarchy\nsplit_plot_data <- \n  split_plot_data_0 %>% \n  mutate(NRATE = factor(NRATE)) %>% \n  # Identify Main Plot\n  # mutate(main = factor(BLOCK:NRATE)) %>% \n  dplyr::select(BLOCK, NRATE, VARIETY, YIELD)\n```\n:::\n\n\n## ii. Dig the data\n\nNow, let's use several functions to explore the data.\n\n### a. glimpse()\n\nFor example, the `glimpse()` function from the dplyr package [@dplyr] allows to take a quick look to the columns in our data frame (it's like a transposed version of `print()`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Glimpse from dplyr\ndplyr::glimpse(split_plot_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 45\nColumns: 4\n$ BLOCK   <chr> \"B1\", \"B1\", \"B1\", \"B1\", \"B1\", \"B1\", \"B1\", \"B1\", \"B1\", \"B1\", \"B…\n$ NRATE   <fct> 0, 0, 0, 50, 50, 50, 80, 80, 80, 110, 110, 110, 140, 140, 140,…\n$ VARIETY <chr> \"Var_1\", \"Var_2\", \"Var_3\", \"Var_1\", \"Var_2\", \"Var_3\", \"Var_1\",…\n$ YIELD   <int> 1938, 3946, 4628, 2038, 4346, 5949, 3837, 4287, 6765, 3466, 49…\n```\n:::\n:::\n\n\n### b. skim()\n\nThen, the `skim()` function from the skimr package [@skimr] allows to take a deeper look to all the variables (columns), creating a quick summary that reports the presence of missing values, etc., etc.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Skim from skimr\nskimr::skim(split_plot_data)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |                |\n|:------------------------|:---------------|\n|Name                     |split_plot_data |\n|Number of rows           |45              |\n|Number of columns        |4               |\n|_______________________  |                |\n|Column type frequency:   |                |\n|character                |2               |\n|factor                   |1               |\n|numeric                  |1               |\n|________________________ |                |\n|Group variables          |None            |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|BLOCK         |         0|             1|   2|   2|     0|        3|          0|\n|VARIETY       |         0|             1|   5|   5|     0|        3|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                 |\n|:-------------|---------:|-------------:|:-------|--------:|:--------------------------|\n|NRATE         |         0|             1|FALSE   |        5|0: 9, 50: 9, 80: 9, 110: 9 |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|    mean|      sd|   p0|  p25|  p50|  p75| p100|hist  |\n|:-------------|---------:|-------------:|-------:|-------:|----:|----:|----:|----:|----:|:-----|\n|YIELD         |         0|             1| 4444.02| 1347.72| 1938| 3389| 4458| 5440| 6950|▅▆▇▆▅ |\n:::\n:::\n\n\n### c. ggplot()\n\nOf course, we shouldn't miss to use ggplot2 for a better look\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot\nsplit_plot_data %>% \n  # Plot\nggplot() + \n  # Boxplots\n  geom_boxplot(aes(x = NRATE, y = YIELD, fill = VARIETY))+\n  geom_jitter(aes(x = NRATE, y = YIELD, fill = VARIETY))+\n  # Plot by site\n  facet_wrap(~VARIETY)+\n  scale_y_continuous(limits = c(0,8000), breaks = seq(0,8000, by=1000))+\n  # Change theme\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/sp_ggplot-1.png){width=672}\n:::\n:::\n\n\n## iii. Models\n\nFor the analysis of split-plot designs we basically need to specify an error term that otherwise the model will not see: the MAIN PLOT ERROR TERM (see Venables and Ripley (2002), pg. 283). By default, the random term that the computer will identify is the one happening at the lowest level in the hierarchy (replication). However, we need to specify that the main plot serves as a kind of block to the design.\n\n### a. nlme::lme\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model without split component\nno_split <- nlme::lme(# Response variable\n                 YIELD ~\n                   # Fixed\n                   0 + NRATE*VARIETY,\n                   # Random error of MAINPLOT (NRATE nested in BLOCK)\n                   random = ~1|BLOCK, \n                   # Data\n                   data = split_plot_data,\n                   # Method\n                   method = \"REML\")\n\n# Model with split component\nsplit_nlme <- nlme::lme(# Response variable\n                 YIELD ~\n                   # Fixed (Removing intercept? Why?)\n                   0 + NRATE*VARIETY,\n                   # Random error of MAINPLOT (NRATE nested in BLOCK)\n                   random = ~1|BLOCK/NRATE, \n                   # Data\n                   data = split_plot_data,\n                   # Method\n                   method = \"REML\")\n\n# Type 3 (when interaction is present)\nAnova(no_split, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: YIELD\n                Chisq Df Pr(>Chisq)    \nNRATE         559.646  5  < 2.2e-16 ***\nVARIETY        22.128  2  1.567e-05 ***\nNRATE:VARIETY  18.117  8    0.02036 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# Let's see the difference between models in terms of DFs\n# summary(no_split)\n# summary(split_nlme)\n```\n:::\n\n\n### b. lmer code (lme4)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit_lme4 <- lme4::lmer(# Response variable\n                   YIELD ~ \n                   # Fixed (Removing intercept? Why?)\n                   0+NRATE*VARIETY +\n                   # Random\n                   (1|BLOCK/NRATE), \n                   # Data\n                   data=split_plot_data)\n\n# Type 3\nAnova(split_lme4, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: YIELD\n                Chisq Df Pr(>Chisq)    \nNRATE         559.646  5  < 2.2e-16 ***\nVARIETY        22.128  2  1.567e-05 ***\nNRATE:VARIETY  18.117  8    0.02036 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## iv. Check assumptions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Single tests\nperformance::check_normality(split_lme4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.910).\n```\n:::\n\n```{.r .cell-code}\nperformance::check_homogeneity(split_lme4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.396).\n```\n:::\n\n```{.r .cell-code}\nperformance::check_autocorrelation(split_lme4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Residuals appear to be independent and not autocorrelated (p = 0.410).\n```\n:::\n\n```{.r .cell-code}\nperformance::check_outliers(split_lme4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: No outliers detected.\n```\n:::\n\n```{.r .cell-code}\nperformance::check_collinearity(split_lme4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Check for Multicollinearity\n\nHigh Correlation\n\n          Term     VIF         VIF 95% CI Increased SE Tolerance\n         NRATE  243.00 [ 168.92,  349.77]        15.59  4.12e-03\n       VARIETY   75.00 [  52.26,  107.83]         8.66      0.01\n NRATE:VARIETY 2025.00 [1406.33, 2916.02]        45.00  4.94e-04\n Tolerance 95% CI\n     [0.00, 0.01]\n     [0.01, 0.02]\n     [0.00, 0.00]\n```\n:::\n\n```{.r .cell-code}\n# Check Plots\nperformance::check_model(split_lme4)\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/sp_check-1.png){width=576}\n:::\n:::\n\n\n## v. Comparisons\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate the comparisons (pairwise)\nsplit_lm4_comparisons <-  \n  split_lme4 %>% \n  # ~ specifies the level of comparison (marginal or interaction)\n  # Since interaction was significant we specify ~ Interaction (Factor1*Factor2)\n  emmeans(., ~NRATE*VARIETY)\n\n# Add letters\nsplit_lm4_comparisons %>% \n  # Compact Letters Display (cld)\n  cld(., \n      # Specify grouped comparisons by...\n      by = \"VARIETY\", \n      # Order\n      decreasing = TRUE, details=FALSE, reversed=TRUE, \n      # Specs\n      alpha=0.05,  adjust = \"tukey\", Letters=LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVARIETY = Var_1:\n NRATE emmean  SE df lower.CL upper.CL .group\n 80      3858 301 30     2901     4815  A    \n 110     3467 301 30     2510     4424  AB   \n 140     3101 301 30     2144     4058  AB   \n 50      2787 301 30     1830     3744  AB   \n 0       2536 301 30     1579     3493   B   \n\nVARIETY = Var_2:\n NRATE emmean  SE df lower.CL upper.CL .group\n 140     5311 301 30     4354     6268  A    \n 110     4948 301 30     3991     5905  AB   \n 80      4611 301 30     3654     5568  AB   \n 50      4039 301 30     3082     4996   BC  \n 0       3186 301 30     2229     4143    C  \n\nVARIETY = Var_3:\n NRATE emmean  SE df lower.CL upper.CL .group\n 80      6587 301 30     5630     7544  A    \n 110     6466 301 30     5509     7423  A    \n 50      5904 301 30     4947     6861  A    \n 140     5359 301 30     4402     6316  AB   \n 0       4501 301 30     3544     5458   B   \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 15 estimates \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: Compact letter displays can be misleading\n      because they show NON-findings rather than findings.\n      Consider using 'pairs()', 'pwpp()', or 'pwpm()' instead. \n```\n:::\n:::\n\n\n# 02. REPEATED MEASURES\n\nNow, we are going to reproduce the analysis I've done for one of my papers [@correndo2021]. Particularly, we are going to reproduce [**Figure 2**](https://www.nature.com/articles/s41598-021-90297-1#Fig2)\n\n![](images/paste-26DDB04C.png)\n\nFor this paper, we have data from 4 different locations. We tested the levels of soil potassium fertility, hereinafter as soil test K (STK), in long-term experiments (2000-2009) where the treatments of interest were: (i) Control (unfertilized), (ii) NPS (fertilized with NPS), and (iii) Pristine conditions (No Ag-history).\n\nAt each plot/sample, the STK was measured at five-consecutive soil depths (0-20, 20-40, 40-60, 60-80, and 80-100 cm). Thus, they we took \"repeated measurements\" over the space.\n\nWe were NOT interested in comparing locations since they had very different previous history, and crop rotation, so confounding effects may have obscured the inference. Therefore, site was not a factor under consideration, and all the analysis were fitted independently by site.\n\n## i. Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read file\nrm_data <- \n  read_excel(\"../data/02_repeated_measures_data.xlsx\", col_names = TRUE) %>% \n  # Create PLOT column to identify subject (Exp. Unit for Rep. Measures)\n  unite(PLOT, BLOCK,TREAT, sep = \"_\", remove=FALSE) %>%\n  # OR\n  # Identify Subplot\n  ungroup() %>% \n  group_by(BLOCK, TREAT) %>% \n  # Create plot ID # Needed for Repeated Measures\n  mutate(plot = cur_group_id(), .after = PLOT) %>% \n  ungroup() %>% \n  mutate(DEPTH = as.factor(DEPTH),\n         depth = as.integer(DEPTH), # Needed for CorAR1\n         BLOCK = factor(BLOCK),\n         SITE = factor(SITE),\n         TREAT = factor(TREAT),\n         # Create a grouping variable (WHY?) # Needed for HetVar\n         GROUP = case_when(TREAT == \"Pristine\" ~ \"Pristine\",\n                           TRUE ~ \"Agriculture\")\n         )\n\n# File online? Try this...(remove \"#\")\n# url_rm <- \"https://raw.githubusercontent.com/adriancorrendo/tidymixedmodelsweb/master/data/02_split_plot_data.csv\"\n\n#rm_data <- read_excel(url_rm, col_names = TRUE)\n```\n:::\n\n\n## ii. Dig the data\n\nNow, let's use several functions to explore the data.\n\n### a. glimpse()\n\nFirst, the `glimpse()` function from dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Glimpse from dplyr\ndplyr::glimpse(rm_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 180\nColumns: 9\n$ SITE  <fct> site_1, site_1, site_1, site_1, site_1, site_1, site_1, site_1, …\n$ PLOT  <chr> \"I_Control\", \"I_Control\", \"I_Control\", \"I_Control\", \"I_Control\",…\n$ plot  <int> 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 5, 5…\n$ TREAT <fct> Control, Control, Control, Control, Control, Control, Control, C…\n$ BLOCK <fct> I, I, I, I, I, II, II, II, II, II, III, III, III, III, III, I, I…\n$ DEPTH <fct> 10, 30, 50, 70, 90, 10, 30, 50, 70, 90, 10, 30, 50, 70, 90, 10, …\n$ STK   <dbl> 105, 83, 103, 110, 127, 119, 98, 106, 107, 109, 132, 100, 96, 10…\n$ depth <int> 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2…\n$ GROUP <chr> \"Agriculture\", \"Agriculture\", \"Agriculture\", \"Agriculture\", \"Agr…\n```\n:::\n:::\n\n\n### b. skim()\n\nThen, the `skim()` function from skmir\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Skim from skimr\nskimr::skim(rm_data)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |rm_data |\n|Number of rows           |180     |\n|Number of columns        |9       |\n|_______________________  |        |\n|Column type frequency:   |        |\n|character                |2       |\n|factor                   |4       |\n|numeric                  |3       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|PLOT          |         0|             1|   5|  12|     0|        9|          0|\n|GROUP         |         0|             1|   8|  11|     0|        2|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                         |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------------------------|\n|SITE          |         0|             1|FALSE   |        4|sit: 45, sit: 45, sit: 45, sit: 45 |\n|TREAT         |         0|             1|FALSE   |        3|Con: 60, NPS: 60, Pri: 60          |\n|BLOCK         |         0|             1|FALSE   |        3|I: 60, II: 60, III: 60             |\n|DEPTH         |         0|             1|FALSE   |        5|10: 36, 30: 36, 50: 36, 70: 36     |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd| p0|    p25| p50|    p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|--:|------:|---:|------:|----:|:-----|\n|plot          |         0|             1|   5.00|  2.59|  1|   3.00|   5|   7.00|    9|▇▇▃▇▇ |\n|STK           |         0|             1| 181.84| 63.09| 74| 138.75| 174| 221.25|  406|▅▇▅▂▁ |\n|depth         |         0|             1|   3.00|  1.42|  1|   2.00|   3|   4.00|    5|▇▇▇▇▇ |\n:::\n:::\n\n\n### c. ggplot()\n\nAnd let's use ggplot2 for a better look\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot\nrm_data %>% \n  dplyr::select(-depth) %>% \n  # Plot\nggplot() + \n  # Boxplots\n  geom_boxplot(aes(x = reorder(DEPTH, desc(DEPTH)), y = STK, fill = TREAT))+\n  # Axis labels\n  labs(x = \"Soil depth (cm)\", y = \"STK (g/m2)\")+\n  # Plot by site\n  facet_wrap(~SITE)+\n  # Flip axes\n  coord_flip()+\n  # Set scale type\n  scale_x_discrete()+\n  # Change theme\n  tidybayes::theme_tidybayes()\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/rm_ggplot-1.png){width=672}\n:::\n:::\n\n\n## iii. Candidate Models\n\nI'm sorry for this, but the most important step is ALWAYS to write down the model.\n\n### a. Formulae\n\n#### m0. Block Fixed\n\nIn a traditional approach blocks are defined as fixed, affecting the mean of the expected value. Yet there is no consensus about treating blocks as fixed or as random. For more information, read @Dixon_2016.\n\nLet's define the model. For simplification (and avoid writing interaction terms), here we are going to consider that $\\tau_i$ is the \"treatment\".\n\n\n$$ y_{ij} = \\mu + \\tau_i + \\beta_j + \\epsilon_{ij} $$\n\n$$ \\epsilon_{ij} \\sim N(0, \\sigma^2_{e} )$$ where $\\mu$ represents the overall mean (if intercept is used), $\\tau_i$ is the effect of treatment-j over $\\mu$, $\\beta_j$ is the effect of block-j over $\\mu$, and $\\epsilon_{ij}$ is the random effect of each experimental unit.\n\n::: {.cell}\n\n```{.r .cell-code}\n# SIMPLEST MODEL\nfit_block_fixed <- function(x){\n  lm(# Response variable\n     STK ~ \n       # Fixed\n       TREAT + DEPTH + TREAT:DEPTH + BLOCK,\n     # Data\n     data = x)\n  }\n```\n:::\n\n#### m1. Block Random\n\nAn alternative approach is considering a MIXED MODEL, where blocks are considered \"random\". Basically, we add a term to the model that it is expected to show a \"null\" overall effect over the mean of the variable of interest but introduces \"noise\". By convention, a random effect is expected to have an expected value equal to zero but a positive variance as follows: $$ y_{ij} = \\mu + \\tau_i + \\beta_j + \\epsilon_{ij} $$ $$ \\beta_j \\sim N(0, \\sigma^2_{b} )$$ $$ \\epsilon_{ij} \\sim N(0, \\sigma^2_{e} )$$ Similar than before, $\\mu$ represents the overall mean (if intercept is used), $\\tau_i$ is the effect of treatment-j over $\\mu$, $\\beta_j$ is the \"random\" effect of block-j over $\\mu$, and $\\epsilon_{ij}$ is the random effect of each experimental unit.\n\nSo what's the difference? Simply specifying this component: $$ \\beta_j \\sim N(0, \\sigma^2_b) $$, which serves to model the variance.\n\nHow do we write that?\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK\nfit_block_random <- function(x){\n  nlme::lme(\n    # Fixed\n    STK ~ TREAT + DEPTH + TREAT:DEPTH,\n    # Random\n    random = ~1|BLOCK,\n    # Data\n    data = x)\n  }\n```\n:::\n\n### Models w/ correlated ERRORS\n\nUntil here all sounds easy. However, we are (potentially) missing a key component. All measures involving DEPTH have been taken from the same \"subjects\" (experimental units/plots). So we do have \"repeated measures\" over space. Thus, it is highly likely that using depth implies the need to adjust the error correlation and covariance structure. Let's explore some options...\n\n#### m2. m1 + CompSymm\n\nCompound symmetry is the simplest covariance structure, where we include a within-subject correlated errors. It is basically the same we do with including BLOCKS as random. We are telling the model that the observations within a given \"depth\" \"share\" something, they have something in common (the error).\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK w/compound symmetry error correlation structure\nfit_corsymm <- function(x){\n  lme(# Response Variable\n      STK ~\n        # Fixed\n        TREAT + DEPTH + TREAT:DEPTH,\n        # Random\n        random = ~1|BLOCK,\n        # Identify subject where repeated measure happens\n        # Plots nested within blocks.\n        correlation = corCompSymm(form = ~ DEPTH |BLOCK/PLOT), \n     # Data   \n     data=x) }\n```\n:::\n\n#### m3. m1 + CorAR1\n\nThe autoregressive of first order structure (CorAR1) considers correlations dependent of the \"distance\". Thus, correlation of error is expected to be the highest between adjacent depths (e.g. 0-20 and 20-40 cm), and a systematically decrease with the distance. For example, the correlation between depth 1 and depth 2 would be $\\rho^{depth_2-depth_1}$, and then less and less, ending with the correlation between depth 5 and depth 1 equal to $\\rho^{depth_5-depth_1}$.\n\n::: callout-caution\nAn important detail here is that CorAR1 structure is only applicable for evenly spaced intervals!\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK w/ auto-regressive of 1st order as error correlation structure\nfit_ar1 <- function(x){lme(STK ~ TREAT + DEPTH + TREAT:DEPTH,\n                       random = ~1|BLOCK,\n                       correlation=corAR1(form=~depth|BLOCK/PLOT),\n                       data=x)}\n```\n:::\n\n#### m4. m3 + HetVar\n\nDid you know that we can \"relax\" the assumption about homogeneity of variance? Oftentimes we have data that shows different variability depending on the level of a given factor or variable.\n\nIn the STK dataset, we observed that the \"Pristine\" treatment (or agriculture condition) present a higher variability compared to Control and NPS treatments, probably linked to higher values of STK. Variance is modeled by adding a \"weight\". This \"weight\" could be a function of a continuous variable (e.g. fertilizer rate?) or, like in our case, based on a \"categorical\" variable.\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK w/compound symmetry error correlation structure + Heterogeneous Variance\nfit_corsymm_hetvar <- function(x){\n  lme(# Response variable\n      STK ~ \n        # Fixed\n        TREAT + DEPTH + TREAT:DEPTH,\n        # Random  \n        random = ~1|BLOCK,\n        # Correlation\n        correlation = corCompSymm(form = ~ depth |BLOCK/PLOT),\n        # Variance\n        weights = varComb(varIdent(form=~1|GROUP)),\n      # Data\n      data=x) }\n```\n:::\n\n### b. Fit\n\nRun the candidate models\n\n::: {.cell}\n\n```{.r .cell-code}\nSTK_models <- \n  rm_data %>% \n  # Let's group data to run multiple locations|datasets at once\n  group_by(SITE) %>% \n  # Store the data per location using nested arrangement\n  nest() %>% \n  # BLOCK as FIXED \n  mutate(model_0 = map(data, fit_block_fixed)) %>% \n  # BLOCK as RANDOM\n  mutate(model_1 = map(data, fit_block_random)) %>% \n  # COMPOUND SYMMETRY\n  mutate(model_2 = map(data, fit_corsymm)) %>% \n  # AUTO-REGRESSIVE ORDER 1\n  mutate(model_3 = map(data, fit_ar1)) %>% \n  # COMPOUND SYMMETRY + HETEROSKEDASTIC\n  mutate(model_4 = map(data,  fit_corsymm_hetvar) ) %>%\n    \n  # Data wrangling\n  pivot_longer(cols = c(model_0:model_4), # show alternative 'contains' model\n               names_to = \"model_id\",\n               values_to = \"model\") %>% \n  # Map over model column\n  mutate(results = map(model, broom.mixed::augment )) %>% \n  # Performance\n  mutate(performance = map(model, broom.mixed::glance )) %>% \n  # Extract AIC\n  mutate(AIC = map(performance, ~.x$AIC)) %>% \n  # Extract coefficients\n  mutate(coef = map(model, ~coef(.x))) %>% \n  # Visual-check plots\n  mutate(checks = map(model, ~performance::check_model(.))) %>% \n  ungroup()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\nCould not compute standard errors from random effects for diagnostic plot.\nHomogeneity of variance could not be computed. Cannot extract residual variance from objects of class 'lme'.\n```\n:::\n:::\n\n### c. Check\n\nChecking assumptions is always important. To learn more about data exploration, tools to detect outliers, heterogeneity of variance, collinearity, dependence of observations, problems with interactions, among others, I highly recommend reading [@Zuur_etal_2010].\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extracting by site\nsite_1_models <- STK_models %>% dplyr::filter(SITE == \"site_1\")\nsite_2_models <- STK_models %>% dplyr::filter(SITE == \"site_3\")\nsite_3_models <- STK_models %>% dplyr::filter(SITE == \"site_4\")\nsite_4_models <- STK_models %>% dplyr::filter(SITE == \"site_2\")\n```\n:::\n\n::: panel-tabset\n## Site 1\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_1_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/unnamed-chunk-2-1.png){width=576}\n:::\n:::\n\n## Site 2\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_2_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/unnamed-chunk-3-1.png){width=576}\n:::\n:::\n\n## Site 3\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_3_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/unnamed-chunk-4-1.png){width=576}\n:::\n:::\n\n## Site 4\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_4_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/unnamed-chunk-5-1.png){width=576}\n:::\n:::\n:::\n\n### d. Selection\n\nCompare models performance\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visual model selection\nbest_STK_models <- \n  STK_models %>% \n  group_by(SITE) %>% \n  # Use case_when to identify the best model\n  mutate(best_model = \n           case_when(AIC == min(as.numeric(AIC)) ~ \"Yes\",\n                     TRUE ~ \"No\")) %>% \n  ungroup()\n\n# Plot\nbest_STK_models %>% \n  ggplot()+\n  geom_point(aes(x = model_id, y = as.numeric(AIC), \n                 color = best_model, shape = best_model), \n             size = 3)+\n  facet_wrap(~SITE)\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/rm_selection-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Final models\nselected_models <- best_STK_models %>% dplyr::filter(best_model == \"Yes\")\n```\n:::\n\n### e. ANOVA\n\nEstimate the effects of factors under study (and their interaction)\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels_effects <- \n  selected_models %>%\n  # Type 3 Sum of Squares (Partial SS, when interactions are present)\n  mutate(ANOVA = map(model, ~Anova(., type = 3)) )\n\n# Extract ANOVAS\nmodels_effects$ANOVA[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: STK\n              Chisq Df Pr(>Chisq)    \n(Intercept) 326.261  1  < 2.2e-16 ***\nTREAT        39.994  2  2.067e-09 ***\nDEPTH        12.637  4   0.013191 *  \nTREAT:DEPTH  21.827  8   0.005247 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n## iv. Means comparison\n\n::: {.cell}\n\n```{.r .cell-code}\n# MULTCOMPARISON\n# emmeans and cld multcomp\n# We need to specify ourselves the most important interaction to perform the comparisons\nmult_comp <- \n  models_effects %>% \n  # Comparisons estimates (emmeans)\n  mutate(mc_estimates = map(model, ~emmeans(., ~ TREAT*DEPTH))) %>% \n  # Assign letters and p-value adjustment (multcomp)\n  mutate(mc_letters = \n           map(mc_estimates, \n               ~as.data.frame( \n                 # By specifies a strata or level to assign the letters\n                 cld(., by = \"DEPTH\", decreasing = TRUE, details=FALSE,\n                     reversed=TRUE, alpha=0.05,  adjust = \"tukey\", Letters=LETTERS))))\n```\n:::\n\n## v. Plot\n\nNow, we are going to reproduce [**Figure 2**](https://www.nature.com/articles/s41598-021-90297-1#Fig2)\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create data frame for plot\nplot_df <- mult_comp %>% \n  dplyr::select(SITE, mc_letters) %>% \n  unnest(mc_letters)\n\n# Define your own colors\nmy_colors <- c(\"#ffaa00\", \"#7E5AA0\", \"#5c9c8c\")\n\n# Create the plot\nSTK_plot <-\n  plot_df %>% \n  # We need to re-express DEPTH from factor to character, and then to numeric\n  mutate(DEPTH = as.numeric(as.character(DEPTH)))  %>% \n  # Re-order levels of the factors\n  mutate(TREAT = fct_relevel(TREAT,\"Control\", \"NPS\", \"Pristine\")) %>% \n  mutate(SITE = fct_relevel(SITE,\"site_1\", \"site_2\", \"site_3\", \"site_4\")) %>% \n  # Create plot\n  ggplot()+\n  # 01. LAYOUT\n  ## Subplots\n  facet_wrap(~SITE, nrow = 2)+\n  ## Axis titles\n  labs(x = \"Soil depth (cm)\", y = bquote(~NH[4]*'OAc-K (g' ~m^-2*')'))+\n  # 02. GEOMETRIES\n  ## i. Points\n  geom_point(aes(x = DEPTH, y = emmean,\n                 fill= TREAT,\n                 shape = TREAT),\n             size = 3, col = \"black\")+\n  ## Adjust shape aesthetics\n  scale_shape_manual(name=\"Fertilizer Scenario\", values=c(24,23,21),\n                     guide=\"legend\")+\n  scale_colour_manual(name=\"Fertilizer Scenario\",\n                    values = my_colors,\n                    guide='legend')+\n  scale_fill_manual(name=\"Fertilizer Scenario\",\n                    values = my_colors,\n                    guide='legend')+\n  ## ii. Add error bar\n  geom_errorbar(width = 0.25, aes(x = DEPTH, color = TREAT, \n                                 ymin = emmean-2*SE, ymax = emmean+2*SE))+\n  ## iii. Add line\n  geom_line(size = 0.5,aes(x = DEPTH, y = emmean, color = TREAT))+\n  # 03. ADJUST XY AXIS\n  ## Reverse the scale\n  scale_x_reverse(breaks=seq(0, 100, 20), limits = c(100,0))+\n  coord_flip()+\n  # 04. THEME\n  theme_bw()+\n  theme(strip.text = element_text(size = rel(1.25)),\n        strip.background = element_blank(),\n        # Grid\n        panel.grid = element_blank(),\n        # Axis\n        axis.title = element_text(size = rel(1.5)),\n        axis.text = element_text(size = rel(1.25), color = \"black\"),\n        # Legend\n        legend.position = \"top\", legend.title = element_blank(),\n        legend.text = element_text(size = rel(1.25))        )\n```\n:::\n\n### i. Figure with caption\n\n::: {layout-col=\"1\"}\n::: {.cell}\n\n```{.r .cell-code}\nSTK_plot\n```\n\n::: {.cell-output-display}\n![](tidymixedmodels_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n**Figure 2**. Soil profiles of STK ($g~m^{-2}$) under three different conditions: pristine soils (green circles), under grain cropping from 2000 to 2009 with no fertilizers added (Control, orange triangles), and under grain cropping from 2000 to 2009 with N, P, plus S fertilization (NPS, purple diamonds). Overlapping error bars indicate absence of significant differences between scenarios by soil depths combinations (Tukey's HSD, p \\< 0.05).\n:::\n\n☺\n\n# 03. ADDING REFERENCES\n\n## i. Citations\n\nAdding references with Quarto has become quite easy. Let's see...\n\n-   Using a **\"\\*.bib\" file**: Figures were produced using the ggplot2 package [@ggplot_book]. Models check were tested with the performance package [@performance_paper].\n\n-   Using **Footnotes**: For example, this is some text with a Footnote[^1], this is a second Footnote[^2]\n\n-   Using **visual editor**: this option introduced by Quarto is simply awesome! 🤩. Let's see. **Insert -\\> Citation** or \"**Crtl + Shift + F8**\". With this option we can look for citations online via DOI, Crossref, etc... and insert them into our document (and to our \\*.bib file).\n\n    ![](images/paste-62A845D2.png)\n\n    ![](images/paste-54EE18F8.png)\n\n[^1]: Citation for Footnote 1\n\n[^2]: Citation for Footnote 2\n\n# BIBLIOGRAPHY\n",
    "supporting": [
      "tidymixedmodels_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}